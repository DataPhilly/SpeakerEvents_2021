# DataPhilly Monthly Speaker Events in 2021
Links to slides and other sites from Monthly Speaker Events hosted by DataPhilly in 2021


<img src="DataPhillyLogo_Final-01.png?raw=true"/>

### March 2021
   * [Video Recording of Event](https://youtu.be/VdR5KmZ3OIU)
   * **March 2021 - Network Neuroscience**
      * Speaker: [Dr. Linden Parkes](https://www.linkedin.com/in/lindenparkes/)
      * Detail: Network Neuroscience is focused on using the tools and techniques from network science to study the brain. Casting the brain as a network of spatially distributed but interconnected units (brain regions) is an intuitive way to formalize and probe our understanding of brain structure and function. Network neuroscientists seek answers to a broad range of questions such as: how is the brain’s complex network organized? How does this organization enable us to engage in sophisticated behaviors? What are the processes that shape the development of this complex network? And to what extent do disruptions to this network link to mental disorder? In this presentation, I will provide an overview of how network neuroscientists analyze data acquired from Magnetic Resonance Imaging; a common imaging technique for studying the human brain in vivo. I will also provide insight into how the Data Science skillset is critical to being a network neuroscientist and will illustrate examples of my own work in the field.
      * [Slides.](https://drive.google.com/file/d/1lXj0LMXzgwWK7K3FOgylvhlx1Sseg5Ke/view)

### April 2021
   * [Video Recording of Event](https://www.youtube.com/watch?v=F2D5UMmy9x4)
   * **Autonomous Object Detection**
      * Speaker: [Ridwan Alam](https://www.linkedin.com/in/ridwanalam/)
      * Detail: With autonomous vehicles taking off in the past several years, it is good to explore the aspect that is instrumental in creating a good autonomous vehicle system: Object Detection. The vehicles’ cameras are feeding the autonomous system what objects it is observing (traffic lights, traffic signs, and other vehicles). The autonomous system then utilizes the information to make a decision to turn left, go straight, and etc. Let’s create an Object Detector model using Darknet and YOLOv4 to see if we can emulate the "eyes of the car".
      * [Github](https://github.com/ridwan102/Autonomous_Vehicle_Object_Detector)
   * **Understanding SHAP Values for Better Model Interpretation**
      * Speaker:  [Dan Pfeffer](https://www.linkedin.com/in/daniel-pfeffer-03259a140/)
      * Detail: Although there have been sweeping improvements in the predictive power of machine-learning models, the interpretation of these models and their results have become more complex. While a single decision tree or basic regression model can easily be interpreted and the importance of features determined, more complicated ensembles or deep-learning models are not as readily understood. SHapley Additive exPlanation (SHAP) values provide an agnostic way of exploring how different features impact model results. Although this concept was originally devised for game theory, it has also enjoyed great success with machine learning. In this talk I will explore SHAP values, how one calculates them and how to apply them to feature importance in machine learning.
      * [Slides](https://drive.google.com/file/d/1R8iCtAIGyOIq_J536IFcdJtS1Wvwadgv/view?usp=sharing)

### June 2021
   * [Video Recording of Event](https://youtu.be/8audd7QpAh0)
   * **Panel Discussion: What Are Hiring Managers Looking for in Candidates?**
      * Speakers: [Jessie Pluto](https://www.linkedin.com/in/jessiepluto), [Anjali Bansal](https://www.linkedin.com/in/anjalibansal), [Robert Cheetham](https://www.linkedin.com/in/rcheetham), [Johanna-Laina Fischer](https://www.linkedin.com/in/johanna-laina-fischer), [Ryan Harrington](https://www.linkedin.com/in/ryanmharrington), [Dave O’ Toole](https://www.linkedin.com/in/daveotoole), [Jason Rodriguez](https://www.linkedin.com/in/jason-rodriguez-95b23874), [Steve Ross](https://www.linkedin.com/in/steveaross), [Oodaye Shukla](https://www.linkedin.com/in/oodaye-shukla)
      * Detail: DataPhilly, R-Ladies Philly, and The Data Lab meetup groups jointly present a panel discussion with hiring managers in the fields of Data Science and Data Engineering!! The job market for data related jobs is hot. But, job seekers usually find disparity between what recruiters say to what hiring managers really want. We hope to close this disconnect through this discussion and to help candidates better prepare for careers in data engineering or data science and to also help employers find better candidates. Whether you are looking for a new job in data or are simply interested in what the hiring process looks like, come and ask questions to our panel of eight hiring managers. Stick around after the Q&A and meet these managers face-to-face.
      * Key Takeaways
        - Skills and Experience: Some jobs require advanced degrees or specialized background. Companies are often looking for candidates with coding and analytic skills that can be honed and trained once hired. Candidates can demonstrate they can apply their experience, even if unrelated, to a technical role.
        - Job Applications: It helps to create customized resumes and cover letters to fit the jobs to which you are applying. However, generic language may help recruiters and HR software determine if you are a good initial candidate. Highlight your data and technical skills, even in the roles that didn't have this as the main focus.
        - Interview Process: Be AUTHENTIC. Good companies are looking for knowledgable and honest people, not robots. Hiring managers want to find people whose career motivations align with the company goals. Be up front about your level of expertise in technologies, programming languages, and experience. You may need to complete one or more coding/logic tests. Prepare questions to ask the interviewers. If available, prepare to talk about any side projects, learning experiences, or volunteer work.

### July 2021
   * [Video Recording of Event](https://youtu.be/PF5RxjsoSNU)
   * **Statistical Paradoxes & Logical Fallacies: Don't Believe the Lies your Data Tells**
      * Speaker: [Christopher Peter Makris](https://www.linkedin.com/in/christopherpetermakris)
      * Detail: I hate to admit it, but your data is lying to you — and more often than you think. Having clean data with high volume, velocity, and variety doesn’t necessarily protect one from the possibility of reaching faulty conclusions to research questions of interest. Despite what you may have learned in Statistics 101, a significant p-value isn’t always groundbreaking. All data can be coerced and bribed to tell any story; thus, as data practitioners, it’s our duty to be cognizant of the possible pitfalls that abound and how to navigate around common traps — responsibly.

        Is more data always better? How can the inclusion or exclusion of data obfuscate a previously held conclusion? In this talk, we’ll address the following paradoxical research questions of interest: 
        Is an observed event truly a trend? How can previously noted behaviors be a marker for the complete opposite behavior in the future? 
        Is an association worth my time/money/effort? 
      * [Slides]

### August 2021
   * **Bayesian Statistics Makes Total Sense**
      * Speaker: [Russ Lavery](https://www.linkedin.com/in/rmlavery/)
      * Detail: This talk is for people that are new to Bayesian statistics or that have to show someone (maybe a manager) the meaning of the terms that Bayesians use. Its deliverable is, using examples and simple math, an understanding of the terms and concepts that show up in programming documentation for Bayesian methods.
        
        This cartoon-formatted talk uses only high school algebra and concentrates on insights inside Bayesian statistics. By offering many, increasingly complicated, examples it develops the vocabulary and concepts of Bayesian statistics. This is a useful talk for someone who wants to read a Bayesian programming manual and be a practitioner without deriving formulas. The goal would be to make attendees comfortable with Bayesian vocabulary and concepts. It will help attendees, when they pick up a programming manual about a Bayesian method, understand what the words mean so they can move on to the coding examples.
        
        Most MS and statistics programs have students derive the two simplest conjugate priors and consider that sufficient training. I maintain that this pedagogy does not give people insights into why Bayesian makes sense. Additionally; focusing on theory and derivations does not help people see Bayesian applications in the real world.
        
        This talk starts at the Bayesian formula shown in undergrad stat 101 and, using examples and cartooning, does end up showing why the steps in the derivation of the beta binomial conjugate prior make sense. While insights are the focus of this talk, being able to, generally, explain the derivation of the Beta-binomial might provide a bit of "street cred" in certain circles.
     
     * [An Introduction to Bayesian Analysis](https://github.com/DataPhilly/SpeakerEvents_2021/blob/main/Supplementary%20Files/An_introcution-to%20Bayesian%20Analysis%20%202019%2010%2002%20c.pdf)

### September 2021
   * **Fresh and Fast: Analytics for Real-time Intelligence and Ad-hoc Applications**
      * Speaker: [Rachel Pedreschi](https://www.linkedin.com/in/rachelpedreschi/)
      * Detail: Digital transformation initiatives have unlocked large and fast-moving data sets including clickstreams, network telemetry, application monitoring and IoT devices. Analytics architectures have not kept pace, with most data still being run through existing “cold analytics” systems and tools designed for smaller and less time-sensitive workloads. “Hot analytics” denotes workloads where the responsiveness of the system is instantaneous and can support self-service data exploration, and where the data is extremely fresh, allowing for more informed decision-making.

        The breadth of analytical systems in the world today demands a clear approach to selecting the right one for a given workload. In this talk, we’ll discuss a temperature-based way of thinking, where workloads get “hotter” as they become more interactive, more concurrent, and more likely to need up-to-the-second data.

        Apache Druid is a modern cloud-native, stream-native, analytics database designed for workflows where fast queries and instant ingest are important. Druid excels at instant data visibility, ad-hoc queries, operational analytics, and handling high concurrency. It is a strong candidate for being the workhorse system for hot analytics.

        In this session Rachel will discuss:
          How to categorize your analytics workloads based on temperature.
          The distinctive attributes of Apache Druid that recommend it for hot analytics where query speed and data freshness is paramount.

      * [Slides](https://docs.google.com/presentation/d/1i3wpNyZDJZ-pAdzoneGQQZD42OGGw1Uk3EocuZhHKfg/view#slide=id.g90c2577835_0_101)
 
### October 2021
   * [Video Recording of Event](https://www.youtube.com/watch?v=enDMje2i_F4)
   * **Multi-Agent Reinforcement Learning: Dodging Tragedy of the Commons with Simple Mechanisms**
      * Speaker: [Quinn Dougherty](https://www.linkedin.com/in/quinn-dougherty/)
      * Detail: Some problems can be described in terms of states, actions, and rewards. A computer program that maximizes rewards in such an environment by selecting actions is called an agent, and the study of these agents is called reinforcement learning. You can select actions with deep learning, leading the research community to advances in playing Go and autonomous vehicles. Naturally, problems and environments arise that are best thought of as a confluence of two or more such agents, the study of which is called multi-agent reinforcement learning. Meanwhile, over in economics, common pool resources are studied as an approximate prisoner's dilemma: if the collective harvests too much, everyone loses, yet if any individual unilaterally implements a sustainable policy others are incentivized not to follow suit. In the literature this is called tragedy of the commons, but economist Elinor Ostrom took an empirical approach and found emergent mechanisms all over the world that caused communities to dodge this outcome. You're asking a natural question: do we want to simulate these environments with multi-agent reinforcement learning, simulate a mechanism suggested by Ostrom, and observe if our agents can dodge tragedy of the commons? In this talk, we will discuss my team's journey through this research question and observe the surprisingly easy interface to Ray's RLlib library for training agents to play multi-player games in python. There will be a follow-along repo.

      * [GitHub](https://github.com/quinn-dougherty/marl-cpr-dataphilly-talk)

### November 2021
   * [Video Recording of Event](https://www.youtube.com/watch?v=oVqW390jZX8)
   * **Crime Analysis - How is Data Science helping keep a community safe?**
      * Speaker: [Capt. Shibu Philipose](https://www.linkedin.com/in/shibu-philipose-91839282/)
      * Detail: When I took over as the Assistant Chief of the Investigative Branch of the Maryland-National Capital Park Police last year, I learned that we collected a lot of data on crime and even had short-term statistics but didn’t do much else with the interpretation of the data information. While we have a person filling the role of a crime analyst, there wasn’t a broader interpretation of the data outside of a week or month of what was occurring within our jurisdiction. I instructed the crime analyst to do more with information. I tasked the crime analyst to take the data for the past three years and create a forecast of future crime based on past history. The data was divided into the four seasons as crime trends tend to change with the seasons for a variety of reasons. We now have seasonal forecasts for crimes and incidents that provide the patrol branch and other branches more focused information to determine their patrol methods, staffing requirements, and overtime details. While some of it may seem like common sense, having data to back up our assessments enables us to better serve our community with the limited resources that we have. In this talk, I will explain the data collection process, the models we developed and the results of our work.

### December 2021
   * [Video Recording of Event](https://youtu.be/D3vbH9klbTk)
   * **Introducing Unstructured Data into your Models**
      * Speakers: [Ari Kaplan](https://www.linkedin.com/in/arikaplan/) and [Joel Gongora](https://www.linkedin.com/in/geodatamex/)
      * Detail: Unstructured data brings its own unique set of challenges including variety & volume of the unstructured data set, denormalized (schema-less) sources, data prep and determining where to start given the two aforementioned "V's" of big data.

        Featuring engineering against this variable data can also present a unique problem demanding an equally unique approach across Text Mining (NLP), GeoSpatial (GIS), Time Series, Visual (Imagery & Computer Vision) and Video in which downsampling, model assisted labeling, and pixel completion and other approaches are required to realistically incorporate these large data sets and types.
