# DataPhilly Monthly Speaker Events in 2021
Links to slides and other sites from Monthly Speaker Events hosted by DataPhilly in 2021


<img src="DataPhillyLogo_Final-01.png?raw=true"/>

### March 2021
   * [Video Recording of Event](https://youtu.be/VdR5KmZ3OIU)
   * **March 2021 - Network Neuroscience**
      * Speaker: [Dr. Linden Parkes](https://www.linkedin.com/in/lindenparkes/)
      * Detail: Network Neuroscience is focused on using the tools and techniques from network science to study the brain. Casting the brain as a network of spatially distributed but interconnected units (brain regions) is an intuitive way to formalize and probe our understanding of brain structure and function. Network neuroscientists seek answers to a broad range of questions such as: how is the brain’s complex network organized? How does this organization enable us to engage in sophisticated behaviors? What are the processes that shape the development of this complex network? And to what extent do disruptions to this network link to mental disorder? In this presentation, I will provide an overview of how network neuroscientists analyze data acquired from Magnetic Resonance Imaging; a common imaging technique for studying the human brain in vivo. I will also provide insight into how the Data Science skillset is critical to being a network neuroscientist and will illustrate examples of my own work in the field.
      * [Slides.](https://drive.google.com/file/d/1lXj0LMXzgwWK7K3FOgylvhlx1Sseg5Ke/view)

### April 2021
   * [Video Recording of Event](https://www.youtube.com/watch?v=F2D5UMmy9x4)
   * **Autonomous Object Detection**
      * Speaker: [Ridwan Alam](https://www.linkedin.com/in/ridwanalam/)
      * Detail: With autonomous vehicles taking off in the past several years, it is good to explore the aspect that is instrumental in creating a good autonomous vehicle system: Object Detection. The vehicles’ cameras are feeding the autonomous system what objects it is observing (traffic lights, traffic signs, and other vehicles). The autonomous system then utilizes the information to make a decision to turn left, go straight, and etc. Let’s create an Object Detector model using Darknet and YOLOv4 to see if we can emulate the "eyes of the car".
      * [Github](https://github.com/ridwan102/Autonomous_Vehicle_Object_Detector)
   * **Understanding SHAP Values for Better Model Interpretation**
      * Speaker:  [Dan Pfeffer](https://www.linkedin.com/in/daniel-pfeffer-03259a140/)
      * Detail: Although there have been sweeping improvements in the predictive power of machine-learning models, the interpretation of these models and their results have become more complex. While a single decision tree or basic regression model can easily be interpreted and the importance of features determined, more complicated ensembles or deep-learning models are not as readily understood. SHapley Additive exPlanation (SHAP) values provide an agnostic way of exploring how different features impact model results. Although this concept was originally devised for game theory, it has also enjoyed great success with machine learning. In this talk I will explore SHAP values, how one calculates them and how to apply them to feature importance in machine learning.
      * [Slides](https://drive.google.com/file/d/1R8iCtAIGyOIq_J536IFcdJtS1Wvwadgv/view?usp=sharing)

### May 2021
   * [Video Recording of Event](https://youtu.be/OSYm9e6BO40 )
   * **Workshop: Geospatial Data Analysis
      * Speaker: [Dr. Fei Jiang](https://www.linkedin.com/in/fei-jiang)
      * Detail: Landcover classification using satellite data (e.g. Landsat8, Sentinel2, etc.) is becoming more and more popular as it is the foundation for many other projects (city planning, farm management, etc.). However, downloading large-sized satellite images (GBs) can be time consuming and requires large memory space. On the other hand, Google Earth Engine Python API provides an easy and fast way to get access to and query satellite data to points of your interest.

In this workshop, we will learn how to use Google Earth Engine Python API to get time-series Sentinel2 data to two groups of points: points in urban area and points in crop lands, and then visualize and compare time-series Sentinel2 spectrums of points in urban areas and crop lands.

If time permits, we will explore how to build up a machine learning model for landcover classification (cropland vs. urban land) using the above time-series data we obtain.
      * [Github](https://github.com/PlantVillage/dataphilly_Jiang)
